{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "INIT_LR = 1e-3\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images(\"Dataset\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    label = 1 if label == \"triple_person\" else 0\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 948, 1: 63}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(np.array(labels), return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awiros-tech/anaconda3/envs/tripleRider/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=28, height=28, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 7s 200ms/step - loss: 0.2559 - accuracy: 0.9022 - val_loss: 0.1653 - val_accuracy: 0.9565\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 4s 178ms/step - loss: 0.2217 - accuracy: 0.9311 - val_loss: 0.1777 - val_accuracy: 0.9565\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 4s 179ms/step - loss: 0.2144 - accuracy: 0.9298 - val_loss: 0.1977 - val_accuracy: 0.9565\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 4s 189ms/step - loss: 0.2117 - accuracy: 0.9339 - val_loss: 0.1839 - val_accuracy: 0.9565\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 0.2191 - accuracy: 0.9311 - val_loss: 0.1686 - val_accuracy: 0.9565\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 4s 187ms/step - loss: 0.2044 - accuracy: 0.9339 - val_loss: 0.1804 - val_accuracy: 0.9565\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 0.2098 - accuracy: 0.9298 - val_loss: 0.1694 - val_accuracy: 0.9565\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 4s 169ms/step - loss: 0.2142 - accuracy: 0.9353 - val_loss: 0.1788 - val_accuracy: 0.9565\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 0.2100 - accuracy: 0.9298 - val_loss: 0.1808 - val_accuracy: 0.9565\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 0.2142 - accuracy: 0.9311 - val_loss: 0.1762 - val_accuracy: 0.9565\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 4s 175ms/step - loss: 0.2205 - accuracy: 0.9298 - val_loss: 0.2043 - val_accuracy: 0.9565\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 4s 175ms/step - loss: 0.2091 - accuracy: 0.9311 - val_loss: 0.1671 - val_accuracy: 0.9565\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 0.2139 - accuracy: 0.9298 - val_loss: 0.1711 - val_accuracy: 0.9565\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 0.2261 - accuracy: 0.9298 - val_loss: 0.2057 - val_accuracy: 0.9565\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 4s 175ms/step - loss: 0.2301 - accuracy: 0.9311 - val_loss: 0.1818 - val_accuracy: 0.9565\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 0.1999 - accuracy: 0.9325 - val_loss: 0.1771 - val_accuracy: 0.9565\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 0.2132 - accuracy: 0.9311 - val_loss: 0.1719 - val_accuracy: 0.9565\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 4s 165ms/step - loss: 0.2178 - accuracy: 0.9298 - val_loss: 0.1688 - val_accuracy: 0.9565\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 4s 170ms/step - loss: 0.2048 - accuracy: 0.9339 - val_loss: 0.1785 - val_accuracy: 0.9565\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.2073 - accuracy: 0.9325 - val_loss: 0.1722 - val_accuracy: 0.9565\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.2038 - accuracy: 0.9311 - val_loss: 0.1816 - val_accuracy: 0.9565\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 0.2002 - accuracy: 0.9325 - val_loss: 0.1708 - val_accuracy: 0.9565\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 4s 169ms/step - loss: 0.2054 - accuracy: 0.9298 - val_loss: 0.1766 - val_accuracy: 0.9565\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 4s 170ms/step - loss: 0.2065 - accuracy: 0.9298 - val_loss: 0.1735 - val_accuracy: 0.9565\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 4s 184ms/step - loss: 0.2043 - accuracy: 0.9321 - val_loss: 0.1768 - val_accuracy: 0.9565\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"model_1.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Santa/Not Santa\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=testX, batch_size=32)\n",
    "\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "triple_rider       0.96      1.00      0.98       242\n",
      "double rider       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.48      0.50      0.49       253\n",
      "weighted avg       0.91      0.96      0.94       253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awiros-tech/anaconda3/envs/tripleRider/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/awiros-tech/anaconda3/envs/tripleRider/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/awiros-tech/anaconda3/envs/tripleRider/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=[\"triple_rider\",\"double rider\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d1099e7dbe4b62249051d2b6a85870902eeb6ff5afbe2c11682c0cafad43d6e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tripleRider')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imutils import paths\n",
    "import imagesize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelNet:\n",
    "    @staticmethod\n",
    "    def LeNet(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        model.add(Conv2D(4, (3, 3), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        \n",
    "        # model.add(Conv2D(16, (5, 5), padding=\"same\"))\n",
    "        # model.add(Activation(\"relu\"))\n",
    "        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(5))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def VGG16(classes):\n",
    "        # initializing the model\n",
    "        model = Sequential()\n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        \n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=4096,activation=\"relu\"))\n",
    "        model.add(Dense(units=4096,activation=\"relu\"))\n",
    "        \n",
    "        model.add(Dense(units=classes, activation=\"softmax\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "INIT_LR = 1e-3\n",
    "BS = 8\n",
    "CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images(\"augData/trialDataset\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nr of Images in the dataset: 2522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Size</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>augData/trialDataset/double_person/image174 (c...</td>\n",
       "      <td>(165, 627)</td>\n",
       "      <td>165</td>\n",
       "      <td>627</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>augData/trialDataset/triple_person/image_0_747...</td>\n",
       "      <td>(338, 519)</td>\n",
       "      <td>338</td>\n",
       "      <td>519</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>augData/trialDataset/triple_person/image_0_882...</td>\n",
       "      <td>(249, 507)</td>\n",
       "      <td>249</td>\n",
       "      <td>507</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>augData/trialDataset/double_person/image131 (c...</td>\n",
       "      <td>(233, 436)</td>\n",
       "      <td>233</td>\n",
       "      <td>436</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>augData/trialDataset/triple_person/image_0_312...</td>\n",
       "      <td>(249, 507)</td>\n",
       "      <td>249</td>\n",
       "      <td>507</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            FileName        Size  Width  \\\n",
       "0  augData/trialDataset/double_person/image174 (c...  (165, 627)    165   \n",
       "1  augData/trialDataset/triple_person/image_0_747...  (338, 519)    338   \n",
       "2  augData/trialDataset/triple_person/image_0_882...  (249, 507)    249   \n",
       "3  augData/trialDataset/double_person/image131 (c...  (233, 436)    233   \n",
       "4  augData/trialDataset/triple_person/image_0_312...  (249, 507)    249   \n",
       "\n",
       "   Height  Aspect Ratio  \n",
       "0     627          0.26  \n",
       "1     519          0.65  \n",
       "2     507          0.49  \n",
       "3     436          0.53  \n",
       "4     507          0.49  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_meta = {}\n",
    "for path in imagePaths: img_meta[path] = imagesize.get(path)\n",
    "\n",
    "# converting the sizes into graph\n",
    "img_meta_df = pd.DataFrame.from_dict([img_meta]).T.reset_index().set_axis(['FileName', 'Size'], axis='columns', inplace=False)\n",
    "img_meta_df[[\"Width\", \"Height\"]] = pd.DataFrame(img_meta_df[\"Size\"].tolist(), index=img_meta_df.index)\n",
    "img_meta_df[\"Aspect Ratio\"] = round(img_meta_df[\"Width\"] / img_meta_df[\"Height\"], 2)\n",
    "\n",
    "print(f'Total Nr of Images in the dataset: {len(img_meta_df)}')\n",
    "img_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Image Resolutions\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "points = ax.scatter(img_meta_df.Width, img_meta_df.Height, color='blue', alpha=0.5, s=img_meta_df[\"Aspect Ratio\"]*100, picker=True)\n",
    "ax.set_title(\"Image Resolution\")\n",
    "ax.set_xlabel(\"Width\", size=14)\n",
    "ax.set_ylabel(\"Height\", size=14)\n",
    "plt.savefig(\"img_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'double_person': 947, 'single_person': 963, 'triple_person': 612}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(np.array(labels), return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awiros-tech/anaconda3/envs/tripleRider/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = modelNet.LeNet(width=28, height=28, depth=3, classes=CLASSES)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 4)         112       \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 28, 28, 4)         0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 14, 14, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 3925      \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,055\n",
      "Trainable params: 4,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/10\n",
      "236/236 [==============================] - 6s 18ms/step - loss: 0.9528 - accuracy: 0.4915 - val_loss: 0.8925 - val_accuracy: 0.5547\n",
      "Epoch 2/10\n",
      "236/236 [==============================] - 4s 15ms/step - loss: 0.8329 - accuracy: 0.5688 - val_loss: 0.7325 - val_accuracy: 0.6387\n",
      "Epoch 3/10\n",
      "236/236 [==============================] - 4s 18ms/step - loss: 0.6785 - accuracy: 0.6925 - val_loss: 0.6411 - val_accuracy: 0.6926\n",
      "Epoch 4/10\n",
      "236/236 [==============================] - 4s 17ms/step - loss: 0.6082 - accuracy: 0.7180 - val_loss: 0.6283 - val_accuracy: 0.6799\n",
      "Epoch 5/10\n",
      "236/236 [==============================] - 4s 16ms/step - loss: 0.5651 - accuracy: 0.7398 - val_loss: 0.6502 - val_accuracy: 0.6656\n",
      "Epoch 6/10\n",
      "236/236 [==============================] - 4s 17ms/step - loss: 0.5471 - accuracy: 0.7483 - val_loss: 0.7174 - val_accuracy: 0.6688\n",
      "Epoch 7/10\n",
      "236/236 [==============================] - 4s 18ms/step - loss: 0.5175 - accuracy: 0.7658 - val_loss: 0.5550 - val_accuracy: 0.7258\n",
      "Epoch 8/10\n",
      "236/236 [==============================] - 4s 18ms/step - loss: 0.5004 - accuracy: 0.7844 - val_loss: 0.5676 - val_accuracy: 0.7100\n",
      "Epoch 9/10\n",
      "236/236 [==============================] - 5s 20ms/step - loss: 0.4842 - accuracy: 0.7977 - val_loss: 0.5465 - val_accuracy: 0.7306\n",
      "Epoch 10/10\n",
      "236/236 [==============================] - 4s 19ms/step - loss: 0.4745 - accuracy: 0.7971 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, batch_size=BS,\n",
    "    validation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"model_1.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on Double and triple rider\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot_multi_class_4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 3)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=testX, batch_size=32)\n",
    "\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "double_person       0.71      0.61      0.66       251\n",
      "single_person       0.69      0.82      0.75       239\n",
      "triple_person       0.91      0.85      0.88       141\n",
      "\n",
      "     accuracy                           0.74       631\n",
      "    macro avg       0.77      0.76      0.76       631\n",
      " weighted avg       0.75      0.74      0.74       631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1),target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out test set with 3 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imagepaths = sorted(list(paths.list_images(\"testSet\")))\n",
    "random.seed(42)\n",
    "random.shuffle(test_imagepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_data = []\n",
    "for imagePath in test_imagepaths:    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    test_labels.append(label)\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = img_to_array(image)\n",
    "    test_data.append(image)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_data = np.array(test_data, dtype=\"float\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "test_labels = lb.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 3)\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(x=test_data, batch_size=32)\n",
    "\n",
    "print(test_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 0, 0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 0, 2, 2, 0, 2, 2,\n",
       "       0, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 0, 0, 1, 1, 2, 1, 0, 1,\n",
       "       1, 0, 2, 0, 1, 2, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 2,\n",
       "       0, 1, 0, 2, 1, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 0, 1, 2, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 2, 0, 2, 2, 0, 1, 1, 2, 1, 1, 0, 0, 2, 2, 0, 1, 2,\n",
       "       0, 2, 0, 1, 2, 0, 0, 2, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 2, 2, 0, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 1,\n",
       "       0])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "double_person       0.23      0.28      0.26        78\n",
      "single_person       0.65      0.60      0.62        80\n",
      "triple_person       0.28      0.24      0.26        63\n",
      "\n",
      "     accuracy                           0.38       221\n",
      "    macro avg       0.39      0.37      0.38       221\n",
      " weighted avg       0.40      0.38      0.39       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels.argmax(axis=1),test_predictions.argmax(axis=1),target_names=lb.classes_))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d1099e7dbe4b62249051d2b6a85870902eeb6ff5afbe2c11682c0cafad43d6e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tripleRider')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
